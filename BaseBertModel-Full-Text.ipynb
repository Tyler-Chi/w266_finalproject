{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea525f7-951c-4c88-b03d-d6381a8c6487",
   "metadata": {},
   "source": [
    "### This notebook will utilize a standard BERT model\n",
    "\n",
    "### Using the full text (capped at 200)\n",
    "\n",
    "### The input to the neural network will be the pooled_token from BERT\n",
    "\n",
    "### Output will be whether or not the question has a score of higher than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a933cc-90e9-4094-b9da-ced5becc5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 13:43:12.980739: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import os\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd83680-90f8-4dfb-96b6-f34f5e1cf80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385834c8-863a-44e9-9ff8-7cbbcf71f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 13:43:16.040132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 13:43:16.059322: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-17 13:43:16.059336: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-17 13:43:16.060054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c439a09-3bbe-4e2f-b604-0d7696435e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the data\n",
    "questions_data = pd.read_csv(\"processed_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3fa014-98b5-4f05-ba68-83797174bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>highest_answer_score</th>\n",
       "      <th>num_answers</th>\n",
       "      <th>has_positive_answer</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Title_Word_Count</th>\n",
       "      <th>Body_Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? &lt;p&gt;I h...</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   Id  OwnerUserId  \\\n",
       "0             0             0           0  469        147.0   \n",
       "1             1             1           1  502        147.0   \n",
       "\n",
       "           CreationDate  Score  \\\n",
       "0  2008-08-02T15:11:16Z     21   \n",
       "1  2008-08-02T17:01:58Z     27   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1            Get a preview JPEG of a PDF on Windows?   \n",
       "\n",
       "                                                Body  highest_answer_score  \\\n",
       "0  <p>I am using the Photoshop's javascript API t...                    12   \n",
       "1  <p>I have a cross-platform (Python) applicatio...                     9   \n",
       "\n",
       "   num_answers  has_positive_answer  \\\n",
       "0            4                    1   \n",
       "1            2                    1   \n",
       "\n",
       "                                           Full_Text  Title_Word_Count  \\\n",
       "0  How can I find the full path to a font from it...                17   \n",
       "1  Get a preview JPEG of a PDF on Windows? <p>I h...                 9   \n",
       "\n",
       "   Body_Word_Count  \n",
       "0               70  \n",
       "1               38  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eca0120-847b-45f6-8023-f2d458c3e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(questions_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9de3c6-7185-4b2b-b446-1ddebac153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = list(train['Full_Text'])\n",
    "train_labels = list(train['has_positive_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29391b61-01ca-45e0-8c4d-772952a34e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = list(test['Full_Text'])\n",
    "test_labels = list(test['has_positive_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c95422-af89-4bbd-8253-a7a3ce83ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 150 # seems like this encompasses most titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff168a49-d47d-4cca-8400-32171262efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = bert_tokenizer(train_examples,\n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_train = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56809d4c-77ef-4c86-bd01-04e952fcbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = bert_tokenizer(test_examples,\n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_test = tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8548389-a9e6-49f7-88c6-ba3011152972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_classification_model(bert_model,\n",
    "                                     train_layers=-1,\n",
    "                                     hidden_size = 200, \n",
    "                                     dropout=0.3,\n",
    "                                     learning_rate=0.00005):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Use the Pooled Output for classification purposes\n",
    "    \"\"\"\n",
    "    if train_layers == -1:\n",
    "        # Freeze all layers of pre-trained BERT model\n",
    "        bert_model.trainable = False\n",
    "\n",
    "    else:\n",
    "        # Restrict training to the train_layers outer transformer layers\n",
    "        retrain_layers = []\n",
    "\n",
    "        for retrain_layer_number in range(train_layers):\n",
    "\n",
    "            layer_code = '_' + str(11 - retrain_layer_number)\n",
    "            retrain_layers.append(layer_code)\n",
    "          \n",
    "        \n",
    "        print('retrain layers: ', retrain_layers)\n",
    "\n",
    "        for w in bert_model.weights:\n",
    "            if not any([x in w.name for x in retrain_layers]):\n",
    "                print('freezing: ', w)\n",
    "                w._trainable = False\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}      \n",
    "\n",
    "    bert_out = bert_model(bert_inputs)\n",
    "\n",
    "    pooled_token = bert_out[1]\n",
    "    #cls_token = bert_out[0][:, 0, :]\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooled_token)\n",
    "\n",
    "\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                                 metrics='accuracy')\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b82ed1c0-9af9-4150-bd35-7fd38c5c024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classification_model = create_bert_classification_model(bert_model, train_layers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f481ffdf-8632-4bb6-870d-c8615cab492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 150)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 150)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
      "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids_layer[0][0]']   \n",
      "                                n_state=(None, 150,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 200)          153800      ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 200)          0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 1)            201         ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,464,273\n",
      "Trainable params: 154,001\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "530d6278-4371-4bc6-83be-b619af3ebb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2567ebb5-7e0e-4cf4-a509-8216421d6b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.5172737948006845, 1: 0.745754880620888}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train.numpy()), y=y_train.numpy())\n",
    "class_weights_dict = {}\n",
    "for i in range(0,2):\n",
    "    class_weights_dict[i] = class_weights[i]\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7be57-c0ab-4530-a373-ec9d56fa4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5363/15183 [=========>....................] - ETA: 8:13:54 - loss: 0.6939 - accuracy: 0.5242"
     ]
    }
   ],
   "source": [
    "bert_classification_model_history = bert_classification_model.fit(\n",
    "    [x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "    y_train,\n",
    "    validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    class_weight=class_weights_dict\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf71416-0b93-4dd5-885a-2bc2406af543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to make confusion matrix:\n",
    "# https://androidkt.com/keras-confusion-matrix-in-tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7b2cc-eeef-4fa5-a9a7-c1b1e467de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/guide/keras/save_and_serialize\n",
    "# how to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a126f-a697-4bb1-9116-a240843c1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classification_model.save('models/bert-model-full-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545ada7-1229-4cf9-8ec7-0f0684ab4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classification_model = keras.models.load_model('models/bert-model-full-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e6906-7037-470a-ac79-32efdd26adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_raw = bert_classification_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089e194-6111-4a33-9e5b-9399f99601d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_raw > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d14474-a24e-41e6-a21a-c95473d1b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee9944-03de-45b3-b041-6a1a6d719ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\"True Neg\", \"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, fmt=\"\", cmap='Blues', annot=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a18acd-805d-46b2-8446-8318548d7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_raw)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd1ac0-6a22-4a66-a577-57bd9cc031c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a70f6-f074-49d5-aded-4ac37854a43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
