{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea525f7-951c-4c88-b03d-d6381a8c6487",
   "metadata": {},
   "source": [
    "### This notebook will utilize a standard BERT model\n",
    "\n",
    "### Just using the Title string as the feature\n",
    "\n",
    "### The input to the neural network will be the pooled_token from BERT\n",
    "\n",
    "### Output will be whether or not the question has a score of higher than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a933cc-90e9-4094-b9da-ced5becc5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import os\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd83680-90f8-4dfb-96b6-f34f5e1cf80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385834c8-863a-44e9-9ff8-7cbbcf71f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c439a09-3bbe-4e2f-b604-0d7696435e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the data\n",
    "questions_data = pd.read_csv(\"processed_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d3fa014-98b5-4f05-ba68-83797174bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>highest_answer_score</th>\n",
       "      <th>num_answers</th>\n",
       "      <th>has_positive_answer</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Title_Word_Count</th>\n",
       "      <th>Body_Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? &lt;p&gt;I h...</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   Id  OwnerUserId  \\\n",
       "0             0             0           0  469        147.0   \n",
       "1             1             1           1  502        147.0   \n",
       "\n",
       "           CreationDate  Score  \\\n",
       "0  2008-08-02T15:11:16Z     21   \n",
       "1  2008-08-02T17:01:58Z     27   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1            Get a preview JPEG of a PDF on Windows?   \n",
       "\n",
       "                                                Body  highest_answer_score  \\\n",
       "0  <p>I am using the Photoshop's javascript API t...                    12   \n",
       "1  <p>I have a cross-platform (Python) applicatio...                     9   \n",
       "\n",
       "   num_answers  has_positive_answer  \\\n",
       "0            4                    1   \n",
       "1            2                    1   \n",
       "\n",
       "                                           Full_Text  Title_Word_Count  \\\n",
       "0  How can I find the full path to a font from it...                17   \n",
       "1  Get a preview JPEG of a PDF on Windows? <p>I h...                 9   \n",
       "\n",
       "   Body_Word_Count  \n",
       "0               70  \n",
       "1               38  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eca0120-847b-45f6-8023-f2d458c3e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(questions_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f9de3c6-7185-4b2b-b446-1ddebac153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = list(train['Title'])\n",
    "train_labels = list(train['has_positive_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29391b61-01ca-45e0-8c4d-772952a34e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = list(test['Title'])\n",
    "test_labels = list(test['has_positive_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55c95422-af89-4bbd-8253-a7a3ce83ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20 # seems like this encompasses most titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff168a49-d47d-4cca-8400-32171262efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = bert_tokenizer(train_examples,\n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_train = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56809d4c-77ef-4c86-bd01-04e952fcbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = bert_tokenizer(test_examples,\n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_test = tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8548389-a9e6-49f7-88c6-ba3011152972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_classification_model(bert_model,\n",
    "                                     train_layers=-1,\n",
    "                                     hidden_size = 200, \n",
    "                                     dropout=0.3,\n",
    "                                     learning_rate=0.00005):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Use the Pooled Output for classification purposes\n",
    "    \"\"\"\n",
    "    if train_layers == -1:\n",
    "        # Freeze all layers of pre-trained BERT model\n",
    "        bert_model.trainable = False\n",
    "\n",
    "    else:\n",
    "        # Restrict training to the train_layers outer transformer layers\n",
    "        retrain_layers = []\n",
    "\n",
    "        for retrain_layer_number in range(train_layers):\n",
    "\n",
    "            layer_code = '_' + str(11 - retrain_layer_number)\n",
    "            retrain_layers.append(layer_code)\n",
    "          \n",
    "        \n",
    "        print('retrain layers: ', retrain_layers)\n",
    "\n",
    "        for w in bert_model.weights:\n",
    "            if not any([x in w.name for x in retrain_layers]):\n",
    "                print('freezing: ', w)\n",
    "                w._trainable = False\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}      \n",
    "\n",
    "    bert_out = bert_model(bert_inputs)\n",
    "\n",
    "    pooled_token = bert_out[1]\n",
    "    #cls_token = bert_out[0][:, 0, :]\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooled_token)\n",
    "\n",
    "\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                                 metrics='accuracy')\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b82ed1c0-9af9-4150-bd35-7fd38c5c024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classification_model = create_bert_classification_model(bert_model, train_layers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f481ffdf-8632-4bb6-870d-c8615cab492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 20)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 20)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
      "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids_layer[0][0]']   \n",
      "                                n_state=(None, 20,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 200)          153800      ['tf_bert_model_1[1][1]']        \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 200)          0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 1)            201         ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,464,273\n",
      "Trainable params: 154,001\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7be57-c0ab-4530-a373-ec9d56fa4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "15183/15183 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.6705"
     ]
    }
   ],
   "source": [
    "bert_classification_model_history = bert_classification_model.fit(\n",
    "    [x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "    y_train,\n",
    "    validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),\n",
    "    batch_size=32,\n",
    "    epochs=2\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bf71416-0b93-4dd5-885a-2bc2406af543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to make confusion matrix:\n",
    "# https://androidkt.com/keras-confusion-matrix-in-tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7b2cc-eeef-4fa5-a9a7-c1b1e467de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/guide/keras/save_and_serialize\n",
    "# how to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a126f-a697-4bb1-9116-a240843c1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classification_model.save('models/bert-model-pooled-token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e6906-7037-470a-ac79-32efdd26adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
