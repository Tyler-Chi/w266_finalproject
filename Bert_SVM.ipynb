{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a24bb9-e675-428a-963f-93efed220b3b",
   "metadata": {},
   "source": [
    "### This will use BERT encodings, to pass into SVM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf410be6-09d0-4b94-b184-866f2fed516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/54414392/convert-sklearn-svm-svc-classifier-to-keras-implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebeff5c-e2e7-4561-a2c5-c32ac63da3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 16:25:49.220283: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import os\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ed82cc-4df3-4f07-b39e-6f45990ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7febad-22cb-4949-908a-ffa234bd2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 16:25:52.370050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-23 16:25:52.391131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-23 16:25:52.391147: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-23 16:25:52.391497: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b593ba9a-2703-48e7-b9e1-bcd55e22850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the data\n",
    "questions_data = pd.read_csv(\"processed_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b575baba-af07-489f-bbe4-28beb1ac7bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>highest_answer_score</th>\n",
       "      <th>num_answers</th>\n",
       "      <th>has_positive_answer</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Title_Word_Count</th>\n",
       "      <th>Body_Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? &lt;p&gt;I h...</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   Id  OwnerUserId  \\\n",
       "0             0             0           0  469        147.0   \n",
       "1             1             1           1  502        147.0   \n",
       "\n",
       "           CreationDate  Score  \\\n",
       "0  2008-08-02T15:11:16Z     21   \n",
       "1  2008-08-02T17:01:58Z     27   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1            Get a preview JPEG of a PDF on Windows?   \n",
       "\n",
       "                                                Body  highest_answer_score  \\\n",
       "0  <p>I am using the Photoshop's javascript API t...                    12   \n",
       "1  <p>I have a cross-platform (Python) applicatio...                     9   \n",
       "\n",
       "   num_answers  has_positive_answer  \\\n",
       "0            4                    1   \n",
       "1            2                    1   \n",
       "\n",
       "                                           Full_Text  Title_Word_Count  \\\n",
       "0  How can I find the full path to a font from it...                17   \n",
       "1  Get a preview JPEG of a PDF on Windows? <p>I h...                 9   \n",
       "\n",
       "   Body_Word_Count  \n",
       "0               70  \n",
       "1               38  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813dbfd6-ffd4-4c77-a401-09d3cedfa8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(questions_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41411297-90fb-4c73-b12b-0d364be30999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = list(train['Title'])\n",
    "train_labels = list(train['has_positive_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dab9ad2-4df3-4bda-9d2d-743a0a494efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = list(test['Title'])\n",
    "test_labels = list(test['has_positive_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a63dc2d-7e58-4b2c-ad26-2f6db31f7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20 # seems like this encompasses most titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05737faf-51fc-461d-9b3c-3fea37b0d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = bert_tokenizer(train_examples,\n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_train = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aceb588c-6037-4096-8e01-298b7bd42363",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = bert_tokenizer(test_examples,\n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_test = tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80998de6-b54d-42bb-8c28-152b4f4d0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_svm_classification_model(bert_model):\n",
    "    bert_model.trainable = False\n",
    "    \n",
    "    # first layer will use bert, to generate the encodings\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "    \n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}\n",
    "    \n",
    "    bert_out = bert_model(bert_inputs)\n",
    "    \n",
    "    pooled_token = bert_out[1]\n",
    "    hidden = tf.keras.layers.Dense(200, activation='relu', name='hidden_layer')(pooled_token)\n",
    "    \n",
    "    # add dropout layer\n",
    "    hidden = tf.keras.layers.Dropout(0.3)(hidden)  \n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(loss='hinge',\n",
    "                                  optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.005),\n",
    "                                  metrics=['accuracy'])\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc09a9b-40c0-4e97-b2d4-8d4199508dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_svm_model = create_bert_svm_classification_model(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc3f6ada-4c1c-4f0f-94ea-cf2b97c68f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 20)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 20)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
      "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids_layer[0][0]']   \n",
      "                                n_state=(None, 20,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 200)          153800      ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 200)          0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 1)            201         ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,464,273\n",
      "Trainable params: 154,001\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_svm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a744f9-2321-4771-8957-3c8164a13947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.5180797810177924, 1: 0.7455603231311309}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train.numpy()), y=y_train.numpy())\n",
    "class_weights_dict = {}\n",
    "for i in range(0,2):\n",
    "    class_weights_dict[i] = class_weights[i]\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25bd5c8f-962a-46eb-a1a4-b18afa0aee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15183/15183 [==============================] - 6362s 419ms/step - loss: 0.9928 - accuracy: 0.5495 - val_loss: 0.8143 - val_accuracy: 0.5431\n"
     ]
    }
   ],
   "source": [
    "bert_svm_model_history = bert_svm_model.fit(\n",
    "    [x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "    y_train,\n",
    "    validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    class_weight=class_weights_dict\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7d842-a3ab-4e88-8c51-05b90f7fb9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670/3796 [====================>.........] - ETA: 5:14"
     ]
    }
   ],
   "source": [
    "y_pred_raw = bert_svm_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e752bce-f286-4121-a39a-772aa9425922",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_raw > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d60f3-27a1-4ce4-b3d4-03f4b7d42fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d0f50-4473-49d3-9603-2e983837eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\"True Neg\", \"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, fmt=\"\", cmap='Blues', annot=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f01f0b-69dd-49b3-b253-4fea7a64fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_raw)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e9423-e56e-4df6-8f21-4e74085b975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc09d7-f8cb-4380-bcaa-d96a8e410438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1bf210-98e3-4aa1-805a-45c7c27187c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"f1 score is: {f1}\")\n",
    "print(f\"precision score is: {precision}\")\n",
    "print(f\"recall score is: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40846881-a781-4528-8308-4e1d35a0fadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
