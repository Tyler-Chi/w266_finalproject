{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0768dff6-f4d9-46f3-bf06-89b5958274a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tychi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/tychi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/tychi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/tychi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/tychi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "# https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4db46e-a8d9-44ac-a22c-b240a39b2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# supposedly this speeds up the training time\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c4d69f4-6686-4453-9229-f83ac3f94701",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71aa9112-042a-4d16-86a7-fa896f113c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_data = pd.read_csv(\"processed_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289d4072-314a-4fef-8462-1c2482e98a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>highest_answer_score</th>\n",
       "      <th>num_answers</th>\n",
       "      <th>has_positive_answer</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Title_Word_Count</th>\n",
       "      <th>Body_Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? &lt;p&gt;I h...</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   Id  OwnerUserId  \\\n",
       "0             0             0           0  469        147.0   \n",
       "1             1             1           1  502        147.0   \n",
       "\n",
       "           CreationDate  Score  \\\n",
       "0  2008-08-02T15:11:16Z     21   \n",
       "1  2008-08-02T17:01:58Z     27   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1            Get a preview JPEG of a PDF on Windows?   \n",
       "\n",
       "                                                Body  highest_answer_score  \\\n",
       "0  <p>I am using the Photoshop's javascript API t...                    12   \n",
       "1  <p>I have a cross-platform (Python) applicatio...                     9   \n",
       "\n",
       "   num_answers  has_positive_answer  \\\n",
       "0            4                    1   \n",
       "1            2                    1   \n",
       "\n",
       "                                           Full_Text  Title_Word_Count  \\\n",
       "0  How can I find the full path to a font from it...                17   \n",
       "1  Get a preview JPEG of a PDF on Windows? <p>I h...                 9   \n",
       "\n",
       "   Body_Word_Count  \n",
       "0               70  \n",
       "1               38  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd58c2ed-7ec5-4476-b838-40d22c709875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "questions_data['Title'] = [title.lower() for title in questions_data['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb664f8-9b0d-47d1-9433-82f699b72900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the words\n",
    "questions_data['Title'] = [word_tokenize(title) for title in questions_data['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a6b169-1d17-4f77-a041-f76cdb0f48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index,entry in enumerate(questions_data['Title']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    questions_data.loc[index,'Title_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8ae290",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_data.to_csv(\"processed_questions_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4b6338-174b-429b-bcb6-70fed831f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X,\\\n",
    "Test_X,\\\n",
    "Train_Y,\\\n",
    "Test_Y\\\n",
    "= model_selection.train_test_split(questions_data['Title_final'],questions_data['has_positive_answer'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29f24170-7247-48ee-8170-a1144e89bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389db614-d826-4402-b442-e157140a467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(questions_data['Title_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X).todense()\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1275f357-5005-4dca-822c-239910e6d015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 12:01:45.572312: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc5ef409-78f0-445f-8c74-5636a8f93de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3f10bcd-c265-4543-824a-b047dab3e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca5ea7-6cdb-4b93-a99e-77ab3a1d1a6d",
   "metadata": {},
   "source": [
    "## Build KERAS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be131147-ec9a-4af0-a918-340587870784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2154e5b-bc36-429d-bbaf-c0f1a8de2fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 12:01:48.273284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-27 12:01:48.320985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-27 12:01:48.321006: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-27 12:01:48.322023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input_shape would be number of features (5000)\n",
    "model.add(Dense(500,input_shape= (5000,)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(500))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid',name='classification_layer'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330389a-6a5c-4583-a5ac-712fa21ea4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(\n",
    "    Train_X_Tfidf,\n",
    "    Train_Y,\n",
    "    validation_data=(Test_X_Tfidf, Test_Y),\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2e8a8-0cb2-41a6-ad03-d32a166313f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
